# app/parse_utils.py
import re
import difflib
from typing import List, Dict, Optional, Tuple

from ocr_utils import run_ocr_easyocr_with_boxes
from preprocess import postprocess_text
from nutrients_dict import NUTRIENT_SYNONYMS
from units_dict import UNIT_REGEX, normalize_unit, is_unit
from constants import NUM_PATTERN, PERCENT_PATTERN

# ğŸ”½ ì¤‘ì•™ ê·œì¹™/ì‚¬ì „ íŒŒë¼ë¯¸í„°ë§Œ rules_dataì—ì„œ ë¶ˆëŸ¬ì˜´ (ë°ì´í„°/íŠœë‹ ë¶„ë¦¬)
from rules_data import (
    COMMON_MISREAD,
    FUZZY_NAME_CUTOFF,
    EASYOCR_CONFIDENCE_MIN,
    EASYOCR_LOOKAHEAD_TOKENS,
)

# -----------------------------
# ì •ê·œí™”/ë§¤ì¹­ ìœ í‹¸
# -----------------------------
def _token_has_digit(tok: str) -> bool:
    return bool(re.search(r"\d", tok))

def normalize_for_nutrition(text: str) -> str:
    """
    ì•ˆì „í•œ ì •ê·œí™”:
    - ì „ê° % â†’ %
    - '96' â†’ '%' (ì˜ˆ: 2696 â†’ 26%)
    - ìˆ«ì í† í°ì— í•œí•´ O/Dâ†’0, i/l/Iâ†’1, Zâ†’7, Sâ†’5, Bâ†’8 êµì •
    """
    text = text.replace("ï¼…", "%")
    text = re.sub(rf"({NUM_PATTERN})\s*96\b", r"\1%", text)

    trans = str.maketrans({
        "O": "0", "o": "0", "D": "0",
        "i": "1", "l": "1", "I": "1",
        "Z": "7", "S": "5", "B": "8",
    })

    fixed_lines = []
    for line in text.splitlines():
        toks = line.split()
        fixed = []
        for t in toks:
            if _token_has_digit(t):
                fixed.append(t.translate(trans))
            else:
                fixed.append(t)
        fixed_lines.append(" ".join(fixed))
    return "\n".join(fixed_lines)

def _cleanup_name_fragment(s: str) -> str:
    """ì´ë¦„ í›„ë³´ ë¬¸ìì—´ì—ì„œ ìˆ«ì/ë‹¨ìœ„/í¼ì„¼íŠ¸ ì”ì—¬ ì œê±° í›„ íŠ¸ë¦¼"""
    s = re.sub(PERCENT_PATTERN, " ", s, flags=re.I)
    s = re.sub(rf"\b({NUM_PATTERN})\s*({UNIT_REGEX})\b", " ", s, flags=re.I)
    s = re.sub(rf"\b{NUM_PATTERN}\b", " ", s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def match_canonical_name(fragment: str) -> Optional[str]:
    """ì‚¬ì „ ê¸°ë°˜ ë§¤ì¹­ (ì •ê·œì‹, êµ­/ì˜/ì•½ì–´/ë³€í˜• í¬í•¨)"""
    for canon, syns in NUTRIENT_SYNONYMS.items():
        for s in syns:
            if re.search(rf"\b{s}\b", fragment, re.IGNORECASE):
                return canon
    return None

def fuzzy_match_name(fragment: str) -> Optional[str]:
    """í¼ì§€ ë§¤ì¹­: í”í•œ ì˜¤ì¸ì‹ êµì • â†’ ì‚¬ì „ ë§¤ì¹­ â†’ ìœ ì‚¬ë„ ë§¤ì¹­"""
    # ì¤‘ì•™ ê·œì¹™ ì‚¬ì „ ìš°ì„  êµì •
    if fragment in COMMON_MISREAD:
        fragment = COMMON_MISREAD[fragment]

    # ì´ë¦„ ì¡°ê°ë§Œ ë‚¨ê¸°ê¸°
    frag = _cleanup_name_fragment(fragment)
    if not frag:
        return None

    canon = match_canonical_name(frag)
    if canon:
        return canon

    # ëª¨ë“  ë³„ì¹­ í‰íƒ„í™”
    all_synonyms = [syn for syns in NUTRIENT_SYNONYMS.values() for syn in syns]
    close = difflib.get_close_matches(frag, all_synonyms, n=1, cutoff=FUZZY_NAME_CUTOFF)
    if close:
        return match_canonical_name(close[0])
    return None

# -----------------------------
# ë¼ì¸ ê¸°ë°˜ íŒŒì„œ (Tesseract ë“±)
# -----------------------------
def parse_nutrition_lines(text: str) -> List[Dict[str, Optional[str]]]:
    """
    í…ìŠ¤íŠ¸ ë¼ì¸ì—ì„œ (ì˜ì–‘ì„±ë¶„/í•¨ëŸ‰/ê¸°ì¤€ì¹˜) ì¶”ì¶œ
    - ê¸°ì¤€ì¹˜/í•¨ëŸ‰ì´ ì—†ì–´ë„ ë²„ë¦¬ì§€ ì•ŠìŒ (None)
    """
    text = normalize_for_nutrition(text)

    rows: List[Dict[str, Optional[str]]] = []

    for raw in text.splitlines():
        line = raw.strip()
        if not line:
            continue

        # ê¸°ì¤€ì¹˜(%)
        percent_str = None
        pm = re.search(PERCENT_PATTERN, line, flags=re.I)
        if pm:
            percent_str = f"{pm.group(1)}%"
            line = re.sub(PERCENT_PATTERN, " ", line, flags=re.I)

        # í•¨ëŸ‰(ìˆ«ì+ë‹¨ìœ„)
        amount_str = None
        m = re.search(rf"\b({NUM_PATTERN})\s*({UNIT_REGEX})\b", line, flags=re.I)
        if m:
            val = m.group(1).replace(",", "")
            unit = normalize_unit(m.group(2))
            amount_str = f"{val} {unit}"
            line = (line[:m.start()] + " " + line[m.end():]).strip()

        # ì´ë¦„ í›„ë³´ ì •ë¦¬ â†’ ë§¤ì¹­
        name_frag = _cleanup_name_fragment(line)
        if not name_frag:
            continue
        canon = fuzzy_match_name(name_frag) or name_frag

        rows.append({"ì˜ì–‘ì„±ë¶„": canon, "í•¨ëŸ‰": amount_str, "ê¸°ì¤€ì¹˜": percent_str})

    return rows

# -----------------------------
# EasyOCR(ë°•ìŠ¤) ê¸°ë°˜ íŒŒì„œ
# -----------------------------
def _split_amount_unit(tok: str) -> Tuple[Optional[str], Optional[str]]:
    """
    '10mg' ê°™ì´ ë¶™ì€ í† í°ì„ ìˆ˜ì¹˜/ë‹¨ìœ„ë¡œ ë¶„ë¦¬
    """
    m = re.match(rf'^({NUM_PATTERN})\s*({UNIT_REGEX})$', tok, flags=re.I)
    if m:
        return m.group(1), normalize_unit(m.group(2))
    return None, None

def parse_nutrition_easyocr(pil, lang: str):
    """
    EasyOCR ê²°ê³¼(detail=1)ë¡œë¶€í„° (ì˜ì–‘ì„±ë¶„/í•¨ëŸ‰/ê¸°ì¤€ì¹˜) êµ¬ì„±
    - ì´ë¦„ í† í° ë°œê²¬ í›„ ê·¼ì ‘ Ní† í° ë²”ìœ„ì—ì„œ ìˆ˜ì¹˜/ë‹¨ìœ„/í¼ì„¼íŠ¸ íƒìƒ‰
    - ì»·ì˜¤í”„/ìœˆë„ìš° í¬ê¸°ëŠ” rules_dataì—ì„œ í†µì¼ ê´€ë¦¬
    """
    results = run_ocr_easyocr_with_boxes(pil, lang)
    tokens = [(t.strip(), c) for (_b, t, c) in results if t and c >= EASYOCR_CONFIDENCE_MIN]

    # ì„œë²„ í›„ì²˜ë¦¬ ì ìš©ë³¸(ê²€ì¦ìš© í…ìŠ¤íŠ¸)
    text_pp = postprocess_text(" ".join([t for t, _ in tokens]))
    text_pp = normalize_for_nutrition(text_pp)

    rows: List[Dict[str, Optional[str]]] = []

    # í† í°ë„ ìˆ«ì/ë‹¨ìœ„ ì¸ì‹ ì‹¤íŒ¨ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ë¯¸ë¦¬ ì¼ë¶€ ì •ê·œí™”
    norm_tokens: List[Tuple[str, float]] = []
    for t, c in tokens:
        # ìˆ«ì í† í°ì˜ í”í•œ ì˜¤ì¸ì‹ë§Œ ì¹˜í™˜
        if _token_has_digit(t):
            t = normalize_for_nutrition(t)
        norm_tokens.append((t, c))

    i = 0
    N = len(norm_tokens)
    while i < N:
        name_tok, _ = norm_tokens[i]
        canon = fuzzy_match_name(name_tok)

        if canon:
            amount_str, percent_str = None, None
            j = i + 1
            max_jump = min(N, i + EASYOCR_LOOKAHEAD_TOKENS)
            while j < max_jump:
                tt, _c = norm_tokens[j]

                # í¼ì„¼íŠ¸ ê°’ (ì˜ˆ: 26%)
                if re.match(rf"^{NUM_PATTERN}%$", tt):
                    percent_str = tt
                    j += 1
                    continue

                # 1) ë¶™ì–´ì„œ ì˜¨ ê²½ìš°: "10mg"
                av, au = _split_amount_unit(tt)
                if av and au and amount_str is None:
                    amount_str = f"{av} {au}"
                    j += 1
                    continue

                # 2) ë¶„ë¦¬ëœ ê²½ìš°: "10" "mg"
                if re.match(rf"^{NUM_PATTERN}$", tt) and amount_str is None:
                    if j + 1 < N:
                        nxt = norm_tokens[j + 1][0]
                        if is_unit(nxt):
                            amount_str = f"{tt} {normalize_unit(nxt)}"
                            j += 2
                            continue

                j += 1

            rows.append({"ì˜ì–‘ì„±ë¶„": canon, "í•¨ëŸ‰": amount_str, "ê¸°ì¤€ì¹˜": percent_str})
            i = j
            continue

        i += 1

    return text_pp, rows
